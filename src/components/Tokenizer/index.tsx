import React, { useState, useMemo, Fragment } from 'react';
import cl100k_base from 'gpt-tokenizer/encoding/cl100k_base';
import o200k_base from 'gpt-tokenizer/encoding/o200k_base';
import styles from './styles.module.scss';
const tokenizers = {
  o200k_base,
  cl100k_base,
};

const pastelColors = [
  "rgba(107,64,216,.3)",
  "rgba(104,222,122,.4)",
  "rgba(244,172,54,.4)",
  "rgba(239,65,70,.4)",
  "rgba(39,181,234,.4)"
];

const TextInput = ({
  value,
  onChange
}: {
  value: string;
  onChange: React.ChangeEventHandler<HTMLTextAreaElement>;
}) => (
  <textarea
    value={value}
    onChange={onChange}
    style={{ width: "100%", height: "200px" }}
  />
);

const TokenizedText = ({ tokens }: { tokens: (string | number)[] }) => (
  <div className={styles['tokenized-text']}>
    {tokens.map((token, index) => (String(token).match(/\n/g)) ? (
      <Fragment key={index}>
        {String(token).match(/\n/g).map((t, inx) => (<span key={`t-${inx}`} style={{ width: '100%' }}><br/></span>))}
      </Fragment>
    ) : (
      <span key={index} style={{ backgroundColor: pastelColors[index % pastelColors.length] }}>
        {String(token).replaceAll(" ", "\u00A0")}
      </span>
    ))}
  </div>
);

type Encoding = "cl100k_base" | "o200k_base";

const Tokenizer = () => {
  const [inputText, setInputText] = useState(
    "–ú–Ω–æ–≥–∏–µ —Å–ª–æ–≤–∞ –∏–ª–∏ —Ö–æ—Ç—è –±—ã –∏—Ö —á–∞—Å—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç –æ–¥–Ω–æ–º—É —Ç–æ–∫–µ–Ω—É. " + "\n" +"–°–∏–º–≤–æ–ª—ã Unicode, —Ç–∞–∫–∏–µ –∫–∞–∫ —ç–º–æ–¥–∑–∏, –º–æ–≥—É—Ç —Ä–∞–∑–±–∏–≤–∞—Ç—å—Å—è –Ω–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ç–æ–∫–µ–Ω–æ–≤, —Å–æ–¥–µ—Ä–∂–∞—â–∏—Ö –±–∞–∑–æ–≤—ã–µ –±–∞–π—Ç—ã: ü§öüèæ\n" +
    "\n" +
    "–ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ —á–∞—Å—Ç–æ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è —Ä—è–¥–æ–º, –º–æ–≥—É—Ç –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å—Å—è –≤–º–µ—Å—Ç–µ: 1234567890."
  );

  const [selectedEncoding, setSelectedEncoding] = useState<Encoding>(
    "o200k_base"
  );


  const onModelSelect = (event: any) => {
    setSelectedEncoding(event.target.value as Encoding);
  };

  const selectEncoding = (
    <div style={{ marginBottom: 8 }}>
      <span>–ú–æ–¥–µ–ª—å: </span>
      <select
        id="encoding-select"
        className={styles['model-select']}
        value={selectedEncoding}
        onChange={onModelSelect}
      >
        <option value="o200k_base">GPT-4o</option>
        <option value="cl100k_base">GPT-4; GPT-3.5-turbo</option>
      </select>
    </div>
  );



  const api = tokenizers[selectedEncoding];
  const encodedTokens = api.encode(inputText);

  const decodedTokens = useMemo(() => {
    const tokens = [];
    for (const token of api.decodeGenerator(encodedTokens)) {
      tokens.push(token);
    }
    return tokens;
  }, [encodedTokens, api]);


  return (
      <div className={`main ${styles['tokenizer-container-centered']}`}>
        <div className={styles['tokenizer-container']}>
          {selectEncoding}
          <div className="tokenizer">
            <TextInput
              value={inputText}
              onChange={(e) => setInputText(e.target.value)}
            />
            <button className={styles['model-btn']} onClick={() => setInputText("")}>–û—á–∏—Å—Ç–∏—Ç—å</button>
          </div>
          <div className={styles['statistics']}>
            <div className={styles['char']}>
              <div className={styles['statistics-text']}>–°–∏–º–≤–æ–ª–æ–≤:</div>
              <span>{inputText.length}</span>
            </div>
            <div className={styles['token']}>
              <div className={styles['statistics-text']}>–¢–æ–∫–µ–Ω–æ–≤:</div>
              <span>{encodedTokens.length}</span>
            </div>
          </div>
          <TokenizedText tokens={decodedTokens}/>
        </div>
      </div>
  );
};

export default Tokenizer;
